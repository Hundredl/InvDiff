{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PREFIX = '/your/path/to/this/repo/InvDiff/data/'\n",
    "WANDB=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no eiil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''\n",
    "export MODEL_NAME=\"CompVis/stable-diffusion-v1-4\"\n",
    "export DATASET_NAME=\"invariant/datasets/fairness/{dataset_name}\"\n",
    "export PATH_PREFIX={path_prefix}\n",
    "\n",
    "\n",
    "export LAMBDA=0\n",
    "export DELTA_TYPE=\"small\"\n",
    "export SOFT_GROUPER={sg}\n",
    "export PATH_GROUPER={pg} # \"t_g2_w3\"\n",
    "export LEARNING_RATE=1e-04\n",
    "export BATCH_SIZE=64\n",
    "export AC_STEPS=1\n",
    "export LR_SCHEDULER=\"cosine\"\n",
    "export WARMUP_STEPS=1000\n",
    "export DELTA_PARAM={dp}\n",
    "export DELTA_RATIO={dr}\n",
    "export HARD_GROUPER_NUM=4\n",
    "\n",
    "accelerate launch --mixed_precision=\"fp16\" src/train_text_to_image.py \\\\\n",
    "  --path_prefix=$PATH_PREFIX \\\\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\\\n",
    "  --train_data_dir=$DATASET_NAME \\\\\n",
    "  --dataset=\"fairness\" \\\\\n",
    "  --resolution=512 --center_crop --random_flip \\\\\n",
    "  --train_batch_size=${{BATCH_SIZE}} \\\\\n",
    "  --gradient_accumulation_steps=${{AC_STEPS}} \\\\\n",
    "  --gradient_checkpointing \\\\\n",
    "  --max_train_steps=10000 \\\\\n",
    "  --learning_rate=${{LEARNING_RATE}} \\\\\n",
    "  --max_grad_norm=1 \\\\\n",
    "  --lr_scheduler=${{LR_SCHEDULER}} --lr_warmup_steps=${{WARMUP_STEPS}} \\\\\n",
    "  --checkpointing_steps=1000 \\\\\n",
    "  --eiil=0 \\\\\n",
    "  --delta=False \\\\\n",
    "  --lambda_value=${{LAMBDA}} \\\\\n",
    "  --delta_ratio=${{DELTA_RATIO}} \\\\\n",
    "  --delta_type=${{DELTA_TYPE}} \\\\\n",
    "  --delta_param=${{DELTA_PARAM}} \\\\\n",
    "  --wandb={wandb} \\\\\n",
    "  --soft_grouper=${{SOFT_GROUPER}} \\\\\n",
    "  --hard_grouper_num=${{HARD_GROUPER_NUM}} \\\\\n",
    "  --output_dir=\"invariant/ckpts/fairness/models/{dataset_name}-noeiil-nodelta-lambda${{LAMBDA}}-delta${{DELTA_RATIO}}-${{DELTA_TYPE}}-deltaparam${{DELTA_PARAM}}-${{SOFT_GROUPER}}-${{HARD_GROUPER_NUM}}-${{PATH_GROUPER}}-bs${{BATCH_SIZE}}-sc${{LEARNING_RATE}}-ac${{AC_STEPS}}-lr${{LR_SCHEDULER}}-wu${{WARMUP_STEPS}}\" \\\\\n",
    "'''\n",
    "import os\n",
    "if not os.path.exists(\"fairness/diff_dataset_no_eiil\"):\n",
    "    os.makedirs(\"fairness/diff_dataset_no_eiil\")\n",
    "\n",
    "ratios = [\n",
    "    [3, 2, 1, 1, 1, 1, 2, 3],\n",
    "]\n",
    "\n",
    "target_dataset = [f'split_fairness_{ratio[0]}{ratio[1]}{ratio[2]}{ratio[3]}{ratio[4]}{ratio[5]}{ratio[6]}{ratio[7]}' for ratio in ratios]\n",
    "\n",
    "sg = \"False\"\n",
    "for pg in [\"t_g2_w3\"]:\n",
    "    for dp in [0]:\n",
    "        for dr in [0]:\n",
    "            for target in target_dataset:\n",
    "                with open(f\"fairness/diff_dataset_no_eiil/run_{dp}_{dr}_sg{sg}_{pg}_tg{target}.sh\", \"w\") as f:\n",
    "                    f.write(template.format(dp=dp, dr=dr, pg=pg, sg=sg, dataset_name=target, path_prefix=PATH_PREFIX, wandb=WANDB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no eiil test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate 1 jobs\n"
     ]
    }
   ],
   "source": [
    "template = '''\n",
    "export MODEL_NAME=\"CompVis/stable-diffusion-v1-4\"\n",
    "export DATASET_NAME=\"invariant/datasets/fairness/split_fairness_11111111\"\n",
    "export PATH_PREFIX={path_prefix}\n",
    "\n",
    "export LAMBDA=0\n",
    "export DELTA_TYPE=\"small\"\n",
    "export SOFT_GROUPER={sg}\n",
    "export PATH_GROUPER={pg} # \"t_g2_w3\"\n",
    "export LEARNING_RATE=1e-04\n",
    "export BATCH_SIZE=64\n",
    "export AC_STEPS=1\n",
    "export LR_SCHEDULER=\"cosine\"\n",
    "export WARMUP_STEPS=1000\n",
    "export DELTA_PARAM={dp}\n",
    "export DELTA_RATIO={dr}\n",
    "export HARD_GROUPER_NUM=4\n",
    "\n",
    "text_num=2\n",
    "sample_num=512\n",
    "\n",
    "for checkpoint_step in 10000 #5000\n",
    "do\n",
    "    python src/test.py \\\\\n",
    "        --path_prefix ${{PATH_PREFIX}} \\\\\n",
    "        --path_dataset ${{DATASET_NAME}} \\\\\n",
    "        --model_name \"{dataset_name}-noeiil-nodelta-lambda${{LAMBDA}}-delta${{DELTA_RATIO}}-${{DELTA_TYPE}}-deltaparam${{DELTA_PARAM}}-${{SOFT_GROUPER}}-${{HARD_GROUPER_NUM}}-${{PATH_GROUPER}}-bs${{BATCH_SIZE}}-sc${{LEARNING_RATE}}-ac${{AC_STEPS}}-lr${{LR_SCHEDULER}}-wu${{WARMUP_STEPS}}\" \\\\\n",
    "        --model_checkpoint_num ${{checkpoint_step}} \\\\\n",
    "        --text_num ${{text_num}} \\\\\n",
    "        --sample_num ${{sample_num}} \\\\\n",
    "        --task_sample True \\\\\n",
    "        --save_sample True\\\\\n",
    "        --task_lpips False \\\\\n",
    "        --task_fid True \\\\\n",
    "        --task_recall True \\\\\n",
    "        --delta False \\\\\n",
    "        --lambda_value ${{LAMBDA}} \\\\\n",
    "        --delta_ratio ${{DELTA_RATIO}} \\\\\n",
    "        --delta_init0 False \\\\\n",
    "        --path_result_root invariant/results/fairness \\\\\n",
    "        --path_ckpt invariant/ckpts/fairness/models \\\\\n",
    "        --task_clip_score True \\\\\n",
    "        --task_bias_score True \\\\\n",
    "        --path_classifier invariant/ckpts/fairness/classifier/classifier_race/resnet18-64-0.0001 \\\\\n",
    "        --num_class_classifier 4\n",
    "done\n",
    "'''\n",
    "import os\n",
    "\n",
    "path = \"fairness/test/diff_dataset_no_eiil\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "ratios = [\n",
    "    [3, 2, 1, 1, 1, 1, 2, 3],\n",
    "]\n",
    "target_dataset = [f'split_fairness_{ratio[0]}{ratio[1]}{ratio[2]}{ratio[3]}{ratio[4]}{ratio[5]}{ratio[6]}{ratio[7]}' for ratio in ratios]\n",
    "sg = \"False\"\n",
    "count = 0\n",
    "for pg in [\"t_g2_w3\"]:\n",
    "    for dp in [0]:\n",
    "        for dr in [0]:\n",
    "            for target in target_dataset:\n",
    "                with open(f\"{path}/run_small_soft_{dp}_{dr}_sg{sg}_{pg}_tg{target}.sh\", \"w\") as f:\n",
    "                    f.write(template.format(dp=dp, dr=dr, pg=pg, sg=sg, dataset_name=target, path_prefix=PATH_PREFIX))\n",
    "                    count += 1\n",
    "print(f'generate {count} jobs')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eiil-delta hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''\n",
    "export MODEL_NAME=\"CompVis/stable-diffusion-v1-4\"\n",
    "export DATASET_NAME=\"invariant/datasets/fairness/{dataset_name}\"\n",
    "export PATH_PREFIX={path_prefix}\n",
    "\n",
    "export LAMBDA={lb}\n",
    "export DELTA_TYPE=\"small\"\n",
    "export SOFT_GROUPER={sg}\n",
    "export PATH_GROUPER={pg} # \"t_g2_w3\"\n",
    "export LEARNING_RATE=1e-04\n",
    "export BATCH_SIZE=64\n",
    "export AC_STEPS=1\n",
    "export LR_SCHEDULER=\"cosine\"\n",
    "export WARMUP_STEPS=1000\n",
    "export DELTA_PARAM={dp}\n",
    "export DELTA_RATIO={dr}\n",
    "export HARD_GROUPER_NUM={hgn}\n",
    "\n",
    "accelerate launch --mixed_precision=\"fp16\" src/train_text_to_image.py \\\\\n",
    "  --path_prefix=$PATH_PREFIX \\\\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\\\n",
    "  --train_data_dir=$DATASET_NAME \\\\\n",
    "  --dataset=\"fairness\" \\\\\n",
    "  --resolution=512 --center_crop --random_flip \\\\\n",
    "  --train_batch_size=${{BATCH_SIZE}} \\\\\n",
    "  --gradient_accumulation_steps=${{AC_STEPS}} \\\\\n",
    "  --gradient_checkpointing \\\\\n",
    "  --max_train_steps=10000 \\\\\n",
    "  --delta_init0=True \\\\\n",
    "  --learning_rate=${{LEARNING_RATE}} \\\\\n",
    "  --max_grad_norm=1 \\\\\n",
    "  --lr_scheduler=${{LR_SCHEDULER}} --lr_warmup_steps=${{WARMUP_STEPS}} \\\\\n",
    "  --checkpointing_steps=1000 \\\\\n",
    "  --eiil=1 \\\\\n",
    "  --delta=True \\\\\n",
    "  --lambda_value=${{LAMBDA}} \\\\\n",
    "  --delta_ratio=${{DELTA_RATIO}} \\\\\n",
    "  --delta_type=${{DELTA_TYPE}} \\\\\n",
    "  --delta_param=${{DELTA_PARAM}} \\\\\n",
    "  --wandb={wandb} \\\\\n",
    "  --soft_grouper=${{SOFT_GROUPER}} \\\\\n",
    "  --hard_grouper_num=${{HARD_GROUPER_NUM}} \\\\\n",
    "  --based_unet_path=\"invariant/ckpts/fairness/models/{dataset_name}-noeiil-nodelta-lambda0-delta0-small-deltaparam0-False-4-t_g2_w3-bs64-sc1e-04-ac1-lrcosine-wu1000/checkpoint-10000\" \\\\\n",
    "  --output_dir=\"invariant/ckpts/fairness/models/{dataset_name}-eiil-delta-lambda${{LAMBDA}}-delta${{DELTA_RATIO}}-${{DELTA_TYPE}}-deltaparam${{DELTA_PARAM}}-${{SOFT_GROUPER}}-${{HARD_GROUPER_NUM}}-${{PATH_GROUPER}}-bs${{BATCH_SIZE}}-sc${{LEARNING_RATE}}-ac${{AC_STEPS}}-lr${{LR_SCHEDULER}}-wu${{WARMUP_STEPS}}\" \\\\\n",
    "'''\n",
    "import os\n",
    "if not os.path.exists(\"fairness/diff_dataset_hard\"):\n",
    "    os.makedirs(\"fairness/diff_dataset_hard\")\n",
    "\n",
    "ratios = [\n",
    "    [3, 2, 1, 1, 1, 1, 2, 3],\n",
    "]\n",
    "\n",
    "target_dataset = [f'split_fairness_{ratio[0]}{ratio[1]}{ratio[2]}{ratio[3]}{ratio[4]}{ratio[5]}{ratio[6]}{ratio[7]}' for ratio in ratios]\n",
    "sg = \"False\"\n",
    "\n",
    "candidate_lb = [1, 10, 50, 100]\n",
    "candidate_lb = [20, 30, 40]\n",
    "candidate_lb = [0.1, 0.5]\n",
    "candidate_lb = [1]\n",
    "\n",
    "hard_group_num = [8]\n",
    "\n",
    "\n",
    "# pretrain\n",
    "for hgn in hard_group_num:\n",
    "    for lb in candidate_lb:\n",
    "        for pg in [\"t_g2_w3\"]:\n",
    "            for dp in [0]:\n",
    "                for dr in [0.4, 0.6, 0.8, 0.9]:\n",
    "                    for target in target_dataset:\n",
    "                        with open(f\"fairness/diff_dataset_hard/run_{dp}_{dr}_sg{sg}_{pg}_tg{target}_lb{lb}_hgn{hgn}.sh\", \"w\") as f:\n",
    "                            f.write(template.format(dp=dp, dr=dr, pg=pg, sg=sg, dataset_name=target, lb=lb, hgn=hgn, path_prefix=PATH_PREFIX, wandb=WANDB))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eiil-delta soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''\n",
    "export MODEL_NAME=\"CompVis/stable-diffusion-v1-4\"\n",
    "export DATASET_NAME=\"invariant/datasets/fairness/{dataset_name}\"\n",
    "export PATH_PREFIX={path_prefix}\n",
    "\n",
    "export LAMBDA={lb}\n",
    "# export DELTA_TYPE=\"small\"\n",
    "export DELTA_TYPE=\"pretrain\"\n",
    "export SOFT_GROUPER={sg}\n",
    "export PATH_GROUPER={pg} # \"t_g2_w3\"\n",
    "export LEARNING_RATE=1e-04\n",
    "export BATCH_SIZE=64\n",
    "export AC_STEPS=1\n",
    "export LR_SCHEDULER=\"cosine\"\n",
    "export WARMUP_STEPS=1000\n",
    "export DELTA_PARAM={dp}\n",
    "export DELTA_RATIO={dr}\n",
    "export HARD_GROUPER_NUM={hgn}\n",
    "\n",
    "accelerate launch --mixed_precision=\"fp16\" src/train_text_to_image.py \\\\\n",
    "    --path_prefix=$PATH_PREFIX \\\\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\\\n",
    "  --train_data_dir=$DATASET_NAME \\\\\n",
    "  --dataset=\"fairness\" \\\\\n",
    "  --resolution=512 --center_crop --random_flip \\\\\n",
    "  --train_batch_size=${{BATCH_SIZE}} \\\\\n",
    "  --gradient_accumulation_steps=${{AC_STEPS}} \\\\\n",
    "  --gradient_checkpointing \\\\\n",
    "  --max_train_steps=10000 \\\\\n",
    "  --learning_rate=${{LEARNING_RATE}} \\\\\n",
    "  --max_grad_norm=1 \\\\\n",
    "  --lr_scheduler=${{LR_SCHEDULER}} --lr_warmup_steps=${{WARMUP_STEPS}} \\\\\n",
    "  --checkpointing_steps=1000 \\\\\n",
    "  --eiil=1 \\\\\n",
    "  --delta=True \\\\\n",
    "  --lambda_value=${{LAMBDA}} \\\\\n",
    "  --delta_ratio=${{DELTA_RATIO}} \\\\\n",
    "  --delta_type=${{DELTA_TYPE}} \\\\\n",
    "  --delta_param=${{DELTA_PARAM}} \\\\\n",
    "  --wandb={wandb} \\\\\n",
    "  --soft_grouper=${{SOFT_GROUPER}} \\\\\n",
    "  --hard_grouper_num=${{HARD_GROUPER_NUM}} \\\\\n",
    "  --based_unet_path=\"invariant/ckpts/fairness/models/{dataset_name}-noeiil-nodelta-lambda0-delta0-small-deltaparam0-False-4-t_g2_w3-bs64-sc1e-04-ac1-lrcosine-wu1000/checkpoint-10000\" \\\\\n",
    "  --path_grouper=\"invariant/ckpts/fairness/groupers/groupers/{dataset_name}/weights_${{PATH_GROUPER}}.pkl\" \\\\\n",
    "  --output_dir=\"invariant/ckpts/fairness/{dataset_name}-eiil-delta-lambda${{LAMBDA}}-delta${{DELTA_RATIO}}-${{DELTA_TYPE}}-deltaparam${{DELTA_PARAM}}-${{SOFT_GROUPER}}-${{HARD_GROUPER_NUM}}-${{PATH_GROUPER}}-bs${{BATCH_SIZE}}-sc${{LEARNING_RATE}}-ac${{AC_STEPS}}-lr${{LR_SCHEDULER}}-wu${{WARMUP_STEPS}}\" \\\\\n",
    "  \n",
    "'''\n",
    "import os\n",
    "if not os.path.exists(\"fairness/diff_dataset_soft\"):\n",
    "    os.makedirs(\"fairness/diff_dataset_soft\")\n",
    "\n",
    "\n",
    "ratios = [\n",
    "    [3, 2, 1, 1, 1, 1, 2, 3],\n",
    "]\n",
    "target_dataset = [f'split_fairness_{ratio[0]}{ratio[1]}{ratio[2]}{ratio[3]}{ratio[4]}{ratio[5]}{ratio[6]}{ratio[7]}' for ratio in ratios]\n",
    "\n",
    "sg = \"True\"\n",
    "\n",
    "candidate_lb = [1, 10, 50, 100]\n",
    "candidate_lb = [20, 30, 40]\n",
    "candidate_lb = [1]\n",
    "\n",
    "\n",
    "hard_group_num = [2, 4]\n",
    "hard_group_num = [8]\n",
    "for hgn in hard_group_num:\n",
    "    for lb in candidate_lb:\n",
    "        for pg in [\"t_g8_w3\", \"t_g8_w5\", \"t_g8_w0\", \"t_g16_w0\", \"t_g16_w3\", \"t_g16_w5\"]:\n",
    "            for dp in [0]:\n",
    "                for dr in [0.4, 0.6, 0.8, 0.9]:\n",
    "                    for target in target_dataset:\n",
    "                        with open(f\"fairness/diff_dataset_soft/run_{dp}_{dr}_sg{sg}_{pg}_tg{target}_lb{lb}_hgn{hgn}.sh\", \"w\") as f:\n",
    "                            f.write(template.format(dp=dp, dr=dr, pg=pg, sg=sg, dataset_name=target, lb=lb, hgn=hgn, path_prefix=PATH_PREFIX, wandb=WANDB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eiil-delta test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''\n",
    "export MODEL_NAME=\"CompVis/stable-diffusion-v1-4\"\n",
    "export DATASET_NAME=\"invariant/datasets/fairness/split_fairness_11111111\"\n",
    "export PATH_PREFIX={path_prefix}\n",
    "\n",
    "export LAMBDA={lb}\n",
    "export DELTA_TYPE=\"small\"\n",
    "export SOFT_GROUPER={sg}\n",
    "export PATH_GROUPER={pg} # \"t_g2_w3\"\n",
    "export LEARNING_RATE=1e-04\n",
    "export BATCH_SIZE=64\n",
    "export AC_STEPS=1\n",
    "export LR_SCHEDULER=\"cosine\"\n",
    "export WARMUP_STEPS=1000\n",
    "export DELTA_PARAM={dp}\n",
    "export DELTA_RATIO={dr}\n",
    "export HARD_GROUPER_NUM={hgn}\n",
    "\n",
    "text_num=2\n",
    "sample_num=512\n",
    "\n",
    "for checkpoint_step in 10000 #5000 3000\n",
    "do\n",
    "    python src/test.py \\\\\n",
    "        --path_prefix ${{PATH_PREFIX}} \\\\\n",
    "        --path_dataset ${{DATASET_NAME}} \\\\\n",
    "        --model_name \"{dataset_name}-eiil-delta-lambda${{LAMBDA}}-delta${{DELTA_RATIO}}-${{DELTA_TYPE}}-deltaparam${{DELTA_PARAM}}-${{SOFT_GROUPER}}-${{HARD_GROUPER_NUM}}-${{PATH_GROUPER}}-bs${{BATCH_SIZE}}-sc${{LEARNING_RATE}}-ac${{AC_STEPS}}-lr${{LR_SCHEDULER}}-wu${{WARMUP_STEPS}}\" \\\\\n",
    "        --model_checkpoint_num ${{checkpoint_step}} \\\\\n",
    "        --text_num ${{text_num}} \\\\\n",
    "        --sample_num ${{sample_num}} \\\\\n",
    "        --task_sample True \\\\\n",
    "        --save_sample True\\\\\n",
    "        --task_lpips False \\\\\n",
    "        --task_fid True \\\\\n",
    "        --task_recall True \\\\\n",
    "        --delta True \\\\\n",
    "        --lambda_value ${{LAMBDA}} \\\\\n",
    "        --delta_ratio ${{DELTA_RATIO}} \\\\\n",
    "        --delta_init0 False \\\\\n",
    "        --path_result_root invariant/results/fairness \\\\\n",
    "        --path_ckpt invariant/ckpts/fairness/models \\\\\n",
    "        --task_clip_score True \\\\\n",
    "        --task_bias_score True \\\\\n",
    "        --path_classifier invariant/ckpts/fairness/classifier/classifier_race/resnet18-64-0.0001 \\\\\n",
    "        --num_class_classifier 4\n",
    "done\n",
    "'''\n",
    "import os\n",
    "\n",
    "path = \"fairness/test/diff_dataset\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "\n",
    "ratios = [\n",
    "    [3, 2, 1, 1, 1, 1, 2, 3],\n",
    "    ]\n",
    "candidate_lb = [1]\n",
    "hard_group_num = [8]\n",
    "target_dataset = [f'split_fairness_{ratio[0]}{ratio[1]}{ratio[2]}{ratio[3]}{ratio[4]}{ratio[5]}{ratio[6]}{ratio[7]}' for ratio in ratios]\n",
    "sg = \"False\"\n",
    "for hgn in hard_group_num:\n",
    "    for lb in candidate_lb:\n",
    "        for pg in [\"t_g2_w3\"]:\n",
    "            for dp in [0]:\n",
    "                for dr in [0.4, 0.6, 0.8, 0.9]:\n",
    "                    for target in target_dataset:\n",
    "                        with open(f\"{path}/run_{dp}_{dr}_sg{sg}_{pg}_tg{target}_lb{lb}_hgn{hgn}.sh\", \"w\") as f:\n",
    "                            f.write(template.format(dp=dp, dr=dr, pg=pg, sg=sg, dataset_name=target, lb=lb, hgn=hgn, path_prefix=PATH_PREFIX))\n",
    "\n",
    "sg = \"True\"\n",
    "for hgn in hard_group_num:\n",
    "    for lb in candidate_lb:\n",
    "        for pg in [\"t_g8_w0\", \"t_g8_w5\"]:\n",
    "            for dp in [0]:\n",
    "                for dr in [0.4, 0.6, 0.8, 0.9]:\n",
    "                    for target in target_dataset:\n",
    "                        with open(f\"{path}/run_{dp}_{dr}_sg{sg}_{pg}_tg{target}_lb{lb}_hgn{hgn}.sh\", \"w\") as f:\n",
    "                            f.write(template.format(dp=dp, dr=dr, pg=pg, sg=sg, dataset_name=target, lb=lb, hgn=hgn, path_prefix=PATH_PREFIX))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grouper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate 6 jobs\n"
     ]
    }
   ],
   "source": [
    "template = '''\n",
    "export MODEL_NAME=\"CompVis/stable-diffusion-v1-4\"\n",
    "export DATASET_NAME=\"invariant/datasets/fairness/{dataset_name}\"\n",
    "\n",
    "echo \"start {dataset_name} samples\"\n",
    "accelerate launch --mixed_precision=\"fp16\"  src/group/generate_train_text_to_image.py \\\\\n",
    "  --path_prefix={path_prefix} \\\\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\\\n",
    "  --train_data_dir=$DATASET_NAME \\\\\n",
    "  --use_ema \\\\\n",
    "  --resolution=512 --center_crop --random_flip \\\\\n",
    "  --train_batch_size=16 \\\\\n",
    "  --gradient_accumulation_steps=1 \\\\\n",
    "  --gradient_checkpointing \\\\\n",
    "  --max_train_steps=15000 \\\\\n",
    "  --learning_rate=1e-05 \\\\\n",
    "  --max_grad_norm=1 \\\\\n",
    "  --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\\\n",
    "  --output_dir=\"invariant/ckpts/fairness/groupers/samples/{dataset_name}/\" \\\\\n",
    "  --based_unet_path=\"invariant/ckpts/fairness/models/{dataset_name}-noeiil-nodelta-lambda0-delta0-small-deltaparam0-False-4-t_g2_w3-bs64-sc1e-04-ac1-lrcosine-wu1000/checkpoint-10000\" \n",
    "\n",
    "echo \"finish {dataset_name} samples\"\n",
    "\n",
    "\n",
    "echo \"start {dataset_name} groupers group_num={group_num} loss_not_zero_weight={loss_not_zero_weight}\"\n",
    "python src/group/train_group.py \\\n",
    "    --path_embedding_file=\"invariant/ckpts/fairness/groupers/samples/{dataset_name}/samples_t.pkl\" \\\n",
    "    --path_prefix=\"{path_prefix}\" \\\n",
    "    --path_groupers=\"invariant/ckpts/fairness/groupers/groupers/{dataset_name}\" \\\n",
    "    --group_num={group_num} \\\n",
    "    --loss_not_zero_weight={loss_not_zero_weight} \\\n",
    "\n",
    "echo \"finish {dataset_name} groupers\"\n",
    "'''\n",
    "\n",
    "template2 = '''\n",
    "export MODEL_NAME=\"CompVis/stable-diffusion-v1-4\"\n",
    "export DATASET_NAME=\"invariant/datasets/fairness/{dataset_name}\"\n",
    "echo \"start {dataset_name} groupers group_num={group_num} loss_not_zero_weight={loss_not_zero_weight}\"\n",
    "python src/group/train_group.py \\\n",
    "    --path_embedding_file=\"invariant/ckpts/fairness/groupers/samples/{dataset_name}/samples_t.pkl\" \\\n",
    "    --path_prefix=\"{path_prefix}\" \\\n",
    "    --path_groupers=\"invariant/ckpts/fairness/groupers/groupers/{dataset_name}\" \\\n",
    "    --group_num={group_num} \\\n",
    "    --loss_not_zero_weight={loss_not_zero_weight} \\\n",
    "\n",
    "echo \"finish {dataset_name} groupers\"\n",
    "\n",
    "'''\n",
    "\n",
    "script_path = \"fairness/grouper/samples\"\n",
    "import os\n",
    "if not os.path.exists(script_path):\n",
    "    os.makedirs(script_path)\n",
    "\n",
    "log_path = \"fairness/grouper/log\"\n",
    "if not os.path.exists(log_path):\n",
    "    os.makedirs(log_path)\n",
    "\n",
    "ratios = [\n",
    "    [3, 2, 1, 1, 1, 1, 2, 3],\n",
    "]\n",
    "\n",
    "target_dataset = [f'split_fairness_{ratio[0]}{ratio[1]}{ratio[2]}{ratio[3]}{ratio[4]}{ratio[5]}{ratio[6]}{ratio[7]}' for ratio in ratios]\n",
    "with open(f\"{script_path}/run_all.sh\", \"w\") as f:\n",
    "    pass\n",
    "count = 0\n",
    "for group_num in [8,16]:\n",
    "    for loss_not_zero_weight in [0,3,5]:\n",
    "        for target in target_dataset:\n",
    "            with open(f\"{script_path}/run_{target}_g{group_num}_w{loss_not_zero_weight}.sh\", \"w\") as f:\n",
    "                if loss_not_zero_weight == 0 and group_num == 8:\n",
    "                    f.write(template.format(dataset_name=target, group_num=group_num, loss_not_zero_weight=loss_not_zero_weight, path_prefix=PATH_PREFIX))\n",
    "                else:\n",
    "                    f.write(template2.format(dataset_name=target, group_num=group_num, loss_not_zero_weight=loss_not_zero_weight, path_prefix=PATH_PREFIX))\n",
    "            \n",
    "            with open(f\"{script_path}/run_all.sh\", \"a\") as f:\n",
    "                f.write(f'echo \"running {target} g{group_num} w{loss_not_zero_weight}\"\\n')\n",
    "                f.write(f'bash scripts/{script_path}/run_{target}_g{group_num}_w{loss_not_zero_weight}.sh >> scripts/{log_path}/run_{target}_g{group_num}_w{loss_not_zero_weight}.log 2>&1 \\n')\n",
    "            count += 1\n",
    "\n",
    "print(f'generate {count} jobs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
